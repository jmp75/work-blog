{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75eb2741-eac7-4dd9-9f9a-0ccd5695130e",
   "metadata": {},
   "source": [
    "# Lithology classification using Hugging Face, part 2\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [hugging-face, NLP, lithology]\n",
    "- author: J-M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6a152-fc40-430f-bcc3-b4d88116a991",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This is a continuation of [Lithology classification using Hugging Face, part 1](https://jmp75.github.io/work-blog/hugging-face/nlp/lithology/2022/06/01/lithology-classification-hugging-face.html).\n",
    "\n",
    "We saw in the previous post that the Namoi lithology logs data had their primary (major) lithology mostly completed. A substantial proportion had None nevertheless, despite descriptions that looked like they would obviously lead to a categorisation. There were many labels, with a long-tailed frequency histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df380d1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Kernel installation\n",
    "\n",
    "Note that mamba seems to not work on `conda install -c huggingface -c conda-forge datasets`; just returns immediately with no output that I can see. Pity because conda install is taking minutes to solve the environment. \n",
    "\n",
    "```sh\n",
    "conda install --force-reinstall mamba -c conda-forge\n",
    "# led to conflicts! Probably related to my installing grayskull and shyaml recently in the base environment. This seems to prevent the instalation of the latest vesion of mamba\n",
    "```\n",
    "\n",
    "```text\n",
    "UnsatisfiableError: The following specifications were found to be incompatible with a past\n",
    "explicit spec that is not an explicit spec in this operation (openssl):\n",
    "\n",
    "  - mamba -> conda[version='4.6.*,<4.13.0|4.6.*|4.7.*,<4.13.0|>=4.7.12,<4.13.0|>=4.8,<4.13.0|>=4.7.12,<4.8']\n",
    "  - mamba -> openssl[version='>=1.1.1f,<1.1.2a|>=1.1.1g,<1.1.2a|>=1.1.1h,<1.1.2a|>=1.1.1i,<1.1.2a|>=1.1.1j,<1.1.2a|>=1.1.1k,<1.1.2a|>=1.1.1l,<1.1.2a|>=1.1.1n,<1.1.2a|>=1.1.1o,<1.1.2a']\n",
    "  - mamba -> openssl[version='>=1.1.1o,<1.1.2a'] -> ca-certificates\n",
    "  - mamba -> pypy3.7[version='>=7.3.7'] -> openssl[version='1.0.*|>=1.0.2o,<1.0.3a|>=1.0.2p,<1.0.3a|>=1.1.1a,<1.1.2a|>=1.1.1e,<1.1.2a|>=3.0.0,<4.0a0|>=3.0.3,<4.0a0|>=3.0.2,<4.0a0|>=1.1.1d,<1.1.2a']\n",
    "\n",
    "The following specifications were found to be incompatible with each other:\n",
    "\n",
    "Output in format: Requested package -> Available versions\n",
    "```\n",
    "\n",
    "`conda remove shyaml grayskull conda-build` In the end figured out I needed `conda install -c conda-forge conda=4.12.0`\n",
    "\n",
    "\n",
    "\n",
    "```sh\n",
    "myenv=hf\n",
    "mamba create -n $myenv python=3.9 -c conda-forge\n",
    "mamba install -n $myenv --yes ipykernel matplotlib sentencepiece scikit-learn -c conda-forge\n",
    "mamba install -n $myenv --yes pytorch=1.11 -c pytorch -c nvidia -c conda-forge\n",
    "mamba install -n $myenv --yes torchvision torchaudio -c pytorch -c nvidia -c conda-forge\n",
    "mamba install -n $myenv --yes -c huggingface -c conda-forge datasets transformers \n",
    "conda activate $myenv\n",
    "python -m ipykernel install --user --name $myenv --display-name \"Hugging Face\"\n",
    "# /home/per202/src/learning-notes/ml/fastai/log.md\n",
    "cd /home/per202/src/learning-notes/ml/fastai\n",
    "# OPTIONAL? mamba install -n $myenv -c pytorch -c conda-forge --file nbdev.txt# \n",
    "```\n",
    "\n",
    "```bat\n",
    "set myenv=hf\n",
    "mamba create -n %myenv% python=3.9 -c conda-forge\n",
    "mamba install -n %myenv% --yes ipykernel matplotlib sentencepiece scikit-learn -c conda-forge\n",
    "mamba install -n %myenv% --yes pytorch=1.11 -c pytorch -c nvidia -c conda-forge\n",
    "mamba install -n %myenv% --yes torchvision torchaudio -c pytorch -c nvidia -c conda-forge\n",
    "mamba install -n %myenv% --yes -c huggingface -c conda-forge datasets transformers \n",
    "conda activate %myenv%\n",
    "python -m ipykernel install --user --name %myenv% --display-name \"Hugging Face\"\n",
    "REM /home/per202/src/learning-notes/ml/fastai/log.md\n",
    "REM cd /home/per202/src/learning-notes/ml/fastai\n",
    "REM OPTIONAL? mamba install -n %myenv% -c pytorch -c conda-forge --file nbdev.txt\n",
    "```\n",
    "\n",
    "```sh\n",
    ". /home/per202/config/baseconda \n",
    "conda env list\n",
    "conda activate hf\n",
    "rm tokz.log ;  nsntrace -o tokz.log python ./tokz.py \n",
    "```\n",
    "\n",
    "Use ctrl-c to end at any time.\n",
    "Downloading: 100%|| 52.0/52.0 [00:00<00:00, 106kB/s]\n",
    "Downloading: 100%|| 578/578 [00:00<00:00, 753kB/s]\n",
    "Downloading: 100%|| 2.35M/2.35M [00:00<00:00, 3.91MB/s]\n",
    "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
    "Finished capturing 3454 packets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab780c4-075b-4bd8-8882-677a5fe59c30",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "fn =  Path('~').expanduser() / \"data/ela/shp_namoi_river/NGIS_LithologyLog.csv\"\n",
    "litho_logs = pd.read_csv(fn, dtype={'FromDepth': str, 'ToDepth': str, 'MajorLithCode': str, 'MinorLithCode': str})\n",
    "MAJOR_CODE='MajorLithCode'\n",
    "MINOR_CODE='MinorLithCode'\n",
    "DESC='Description'\n",
    "\n",
    "#from ela.textproc import token_freq, plot_freq\n",
    "\n",
    "from collections import Counter\n",
    "def token_freq(tokens, n_most_common = 50):\n",
    "    list_most_common=Counter(tokens).most_common(n_most_common)\n",
    "    return pd.DataFrame(list_most_common, columns=[\"token\",\"frequency\"])\n",
    "\n",
    "def plot_freq(dataframe, y_log = False, x='token', figsize=(15,10), fontsize=14):\n",
    "    \"\"\"Plot a sorted histogram of work frequencies\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas dataframe): frequency of tokens, typically with colnames [\"token\",\"frequency\"]\n",
    "        y_log (bool): should there be a log scale on the y axis\n",
    "        x (str): name of the columns with the tokens (i.e. words)\n",
    "        figsize (tuple):\n",
    "        fontsize (int):\n",
    "\n",
    "    Returns:\n",
    "        barplot: plot\n",
    "\n",
    "    \"\"\"\n",
    "    p = dataframe.plot.bar(x=x, figsize=figsize, fontsize=fontsize)\n",
    "    if y_log:\n",
    "        p.set_yscale(\"log\", nonposy='clip')\n",
    "    return p\n",
    "\n",
    "\n",
    "litho_classes=litho_logs[MAJOR_CODE].values\n",
    "df_most_common= token_freq(litho_classes, 50)\n",
    "plot_freq(df_most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d636dc61-9628-4ad5-8e3d-559e2b7b82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import Dataset,DatasetDict\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f1cb62-dbb2-4a4c-8d1a-67a61b7aee00",
   "metadata": {},
   "source": [
    "\n",
    "* For the sake of applying HF, can I reduce the number of target labels.\n",
    "* unbalanced data sets: https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14539625-66ca-4ec7-971e-73859f5aa579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_desc_for_code(major_code, n=50, seed=None):\n",
    "    is_code = litho_logs[MAJOR_CODE] == major_code\n",
    "    coded = litho_logs.loc[is_code][DESC]\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    return coded.sample(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341f6d3-3216-4223-9428-41aad2ff098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_desc_for_code('UNKN', seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189ce333-8dfd-443f-8e51-edbacfdbb8ec",
   "metadata": {},
   "source": [
    "The \"unknown\" category is rather interesting in fact, and worth keeping as a valid class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f1111b-199d-42f6-90da-159cf7b2ff21",
   "metadata": {},
   "source": [
    "## Subsetting\n",
    "\n",
    "Let's keep \"only\" the main labels, for the sake of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9845e0-dd92-435c-b3df-9117254ca549",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_kept = df_most_common['token'][:17].values\n",
    "labels_kept = labels_kept[labels_kept != 'None']\n",
    "labels_kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeca839",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept = [x in labels_kept for x in litho_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26602a56",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "litho_logs_kept = litho_logs[kept]\n",
    "litho_logs_kept.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f0a828",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "MAJOR_CODE_INT='MajorLithoCodeInt'\n",
    "from datasets import ClassLabel\n",
    "labels = ClassLabel(names=labels_kept)\n",
    "litho_logs_kept[MAJOR_CODE_INT] = [labels.str2int(x) for x in litho_logs_kept[MAJOR_CODE].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b12cf53-a316-4107-8769-3112762cc4b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Class imbalance\n",
    "\n",
    "Even our subset of 16 classes is rather imbalanced; the \"clay\" label is more than 30 times that of \"coal\" just by eyeballing. \n",
    "\n",
    "The post by Jason Brownlee [8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset). One of them is to resample from labels, perhaps with replacement, to equalise classes. It is a relatively easy approach to implement, but there are issues growing with the level of imbalance. \n",
    "\n",
    "The video [Simple Training with the 🤗 Transformers Trainer (at 669 seconds)](https://youtu.be/u--UVvH-LIQ?t=669) also explains the issues with imbalances and crude resampling. It offers instead a solution with class weighting that is more robust. That approach is evoked in Jason's post, but the video has a \"Hugging Face style\" implementation ready to repurpose.\n",
    "\n",
    "### Resample with replacement\n",
    "\n",
    "Just for information, what we'd do with a relatively crude resampling may be:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_major_lithocode(dframe, code, n=10000, seed=None):\n",
    "    x = dframe[dframe[MAJOR_CODE] == code]\n",
    "    replace = n > len(x)\n",
    "    return x.sample(n=n, replace=replace, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_major_lithocode(litho_logs_kept, 'CLAY', n=10, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c7c1c-d26d-4ac8-acb7-466fd68fae0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "balanced_litho_logs = [sample_major_lithocode(litho_logs_kept, code, n=10000, seed=0) for code in labels_kept]\n",
    "balanced_litho_logs = pd.concat(balanced_litho_logs)\n",
    "balanced_litho_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d079a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_freq(token_freq(balanced_litho_logs[MAJOR_CODE].values, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b39071-76bc-47be-9ed0-e43aaa5030ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dealing with imbalanced classes with weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba803906-962a-45b5-beb7-3293b30e0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_counts = litho_logs_kept[MAJOR_CODE].value_counts().sort_index()\n",
    "sorted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0c271-e04b-4a10-89cf-b175bcab4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_counts / sorted_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e9d3f-7a35-4f93-8371-3e5b883b8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = (1 - sorted_counts / sorted_counts.sum()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc787f1f-882e-46d4-9a51-95c7b0396b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46982a5a-704a-4376-9671-ed91b97719c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c1451d-db34-4335-9db3-0745f1e859c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.from_numpy(class_weights).float().to(\"cuda\")\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533be356",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'microsoft/deberta-v3-small'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f2e199-d4fe-4077-8a2a-eda4e5aee6f9",
   "metadata": {},
   "source": [
    "Note: once when running the cell below it was not completing. it got stuck for 500 seconds and when interupting the execution the stack trace was showing it stuck `sock.connect(sa)`. There seems to be a timeout at play, but not clear at all from the documentation of from_pretrained if there is a way to specify it and what its default is. Irritating.\n",
    "\n",
    "'Active cell trusted. 20 of 52 cells trusted.'\n",
    "\n",
    "Try to \"Ctrl-Shift-C\" then \"Trust Notebook\", but this had no benefit. AutoTokenizer.from_pretrained still spins forever without feedback to the user. Poor UX.\n",
    "\n",
    "```text\n",
    "CPU times: user 504 ms, sys: 57.9 ms, total: 562 ms\n",
    "Wall time: 14min 13s\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffcb883-d2c9-405f-a448-e0688efa9efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "p = Path('./tokz_pretrained')\n",
    "if p.exists():\n",
    "    tokz = AutoTokenizer.from_pretrained(p)\n",
    "else:\n",
    "    tokz = AutoTokenizer.from_pretrained(model_nm)\n",
    "    tokz.save_pretrained('./tokz_pretrained')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6b6a3-b2d8-4294-8249-8e7251b9e56b",
   "metadata": {},
   "source": [
    "Let's see what this does on a typical lithology description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ccaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokz.tokenize('CLAY, VERY SANDY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479d50ae-36ea-455d-b7e0-9bc549a42746",
   "metadata": {},
   "source": [
    "Well, the vocabulary is probably case sensitive and all the descriptions being uppercase in the source data are likely problematic. Let's check on lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b977ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokz.tokenize('clay, very sandy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf73fd-0f51-4091-a4b2-8cac9ea9f0a9",
   "metadata": {},
   "source": [
    "This looks better. So let's change the descriptions to lowercase; we are not loosing any relevent information in this case, I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd22306",
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_logs_kept[DESC] = litho_logs_kept[DESC].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5876f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_logs_kept_mini = litho_logs_kept[[MAJOR_CODE_INT, DESC]]\n",
    "litho_logs_kept_mini.sample(n=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6cb10-d14f-4ec0-8068-ac96fe3ae7b1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# NLP for beginers\n",
    "ds = Dataset.from_pandas(litho_logs_kept_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b566d0-01e4-4849-9da3-3a13cccfe1b4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# https://youtu.be/_BZearw7f0w?list=PLo2EIpI_JMQvWfQndUesu0nPBAtZ9gP1o&t=150\n",
    "# Cheating a bit on guessing the length (max is 90 tokens)\n",
    "max_length=128\n",
    "\n",
    "def tok_func(x): \n",
    "    return tokz(x[DESC], padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b334bc-8bf6-4cc7-88b4-3db180c30324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tok_ds = ds.map(tok_func, batched=True) \n",
    "# Nope, no can do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae491a9-4934-4703-8ce0-b29024d1804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_ds = ds.map(tok_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b8730",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_ds_tmp = tok_ds[:5]\n",
    "tok_ds_tmp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9412e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "len(tok_ds_tmp['input_ids'][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522e27f-5452-461a-aac5-1283073e4bae",
   "metadata": {},
   "source": [
    "Once again, the `from_pretrained` method takes ages to complete, yet the effective CPU time is minimal. No idea what is going on. \n",
    "\n",
    "So, better cache the model locally just in case this behavior persists.\n",
    "\n",
    "```text\n",
    "Downloading: 100%\n",
    "273M/273M [00:25<00:00, 11.6MB/s]\n",
    "CPU times: user 4.38 s, sys: 1.17 s, total: 5.55 s\n",
    "Wall time: 19min 16s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8a7b0-fe3b-4e7b-9777-6e1e6124d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('./model_pretrained')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28159be8-f52f-493f-9f7e-ba11a0d49993",
   "metadata": {},
   "source": [
    "As I write this by elaborating from Jeremy Howard'd notebook, I should mention the misunderstanding I have with num_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000feb4d-7a37-4aa3-85b4-e28f562465d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(labels_kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78fa880-3100-492e-ac22-ea8b54420389",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p.exists():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(p, num_labels=num_labels)\n",
    "else:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=num_labels)    \n",
    "    model.save_pretrained(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d88f6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c718455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/1pedAIvTWXk?list=PLo2EIpI_JMQvWfQndUesu0nPBAtZ9gP1o&t=143\n",
    "litho_desc_list = [x for x in litho_logs_kept_mini[DESC].values]\n",
    "input_descriptions = tokz(litho_desc_list, padding=True, truncation=True, max_length=256, return_tensors='pt')\n",
    "input_descriptions['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d94855",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# model(input_descriptions['input_ids'][:5,:], attention_mask=input_descriptions['attention_mask'][:5,:]).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f135e-a936-4d7b-9209-723a27f47d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9e2d1-eb58-4053-b220-057d134f05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd89184-769b-4a31-8773-eec4bd5be632",
   "metadata": {},
   "source": [
    "Transformers always assumes that your labels has the column name labels,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96641167-e9a7-4317-8b6b-4f077e39254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_ds = tok_ds.rename_columns({MAJOR_CODE_INT:'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_ds.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db834a45-676a-4d1e-9da7-bff9d98d6243",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "epochs = 4\n",
    "\n",
    "lr = 8e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66ba17-070c-4050-b71b-c5b24a4977ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(output_dir='./litho_outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802eac87-b5ce-41d2-8b4c-8bd4d0e4337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dds = tok_ds.train_test_split(0.25, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d8a5a-87ed-4f0b-83e9-5d3fca3210cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0009aa-1653-4dc8-8e60-83ab3618a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c947418a-3ca0-42d2-9b6f-2c78a3423a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a94f1-d3a7-437d-914d-4d7dad1112ab",
   "metadata": {},
   "source": [
    "`metric = load_metric(\"accuracy\")` took an awful:\n",
    "\n",
    "```text\n",
    "CPU times: user 92.7 ms, sys: 70.7 ms, total: 163 ms\n",
    "Wall time: 6min 41s\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e127d2-9e76-42bd-ac9f-d66bfc7cdced",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# metric = load_metric(\"accuracy\")\n",
    "\n",
    "# # ImportError: To be able to use accuracy, you need to install the following dependencies['sklearn'] using 'pip install sklearn' for instance'\n",
    "# # (hf) per202@keywest-bm:~$ mamba install -c conda-forge scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4c295-07a5-4302-bec2-4f695f6d232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Jeremy's notebook:\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151d98e-af42-43c5-919b-5b85cf80361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Trainer to compute Custom Loss Function\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Feed inputs to model and extract logits\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # Extract Labels\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # Define loss function with class weights\n",
    "        loss_func = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        # Compute loss\n",
    "        loss = loss_func(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e5441-df89-4e56-9c76-f7b6bb00a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18700e87-9769-4a15-a138-acbce78ad03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    labels = eval_pred.label_ids\n",
    "    predictions = eval_pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    return {\"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f682b7-31cb-4d98-8519-3953f4bd7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./hf_training\"\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "lr = 8e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5a0c0-e0f0-4952-a1d8-97e2bdab8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir = output_dir,\n",
    "                                  num_train_epochs=epochs, \n",
    "                                  learning_rate=lr,\n",
    "                                  lr_scheduler_type='cosine', \n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size * 2,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  logging_steps=len(dds['train']),\n",
    "                                  fp16=True,\n",
    "                                  push_to_hub=False,\n",
    "                                  report_to='none')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddeb9c9-96d8-4118-9c36-2a5eb86e3a88",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = model.to(\"cuda:0\")\n",
    "# otherwise trainer.train will give: \n",
    "# RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c24545",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                  args=training_args, \n",
    "                  train_dataset=dds['train'],\n",
    "                  eval_dataset=dds['test'],\n",
    "                  tokenizer=tokz, \n",
    "                  compute_metrics=compute_metrics)\n",
    "\n",
    "# https://github.com/nlp-with-transformers/notebooks/issues/31#issuecomment-1075369210 ???\n",
    "# old_collator = trainer.data_collator\n",
    "# trainer.data_collator = lambda data: dict(old_collator(data))\n",
    "\n",
    "# (hf) per202@keywest-bm:~/src/work-blog$ mamba list | grep hugging\n",
    "# datasets                  2.2.2                      py_0    huggingface\n",
    "# huggingface_hub           0.7.0                      py_0    huggingface\n",
    "# sacremoses                master                     py_0    huggingface\n",
    "# transformers              4.11.3                     py_0    huggingface\n",
    "\n",
    "\n",
    "# mamba update -c conda-forge transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f965b-c456-4d60-a9a9-a553eb8a8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39110291-075e-4166-9e31-8430544a07de",
   "metadata": {},
   "source": [
    "\n",
    "```text\n",
    "ValueError: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length.\n",
    "```\n",
    "\n",
    "OK. But where? this comes from transformers/tokenization_utils_base so presumably something to do with the settings of the tokeniser. Besides, from googling for similar error messages I am not convinced following the suggestion blindly is the right approach.\n",
    "\n",
    "The youtube video has factorised labels, int coding for strings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b02dac-5051-4d2e-89db-437dfb48f273",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dtrain = dds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa9eeb-f950-4653-a419-a324bc36959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaea249-279e-424e-a909-43cca61b3782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a35eddb98a7327eba2e298515362c4b3c452739b41fb0a1c2c85ed15fb6f7656"
  },
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Hugging Face",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
