{
  
    
        "post0": {
            "title": "Victorian Water Measurement Information System",
            "content": "About . Trying to retrieve time series or streamflow measurements via a REST API. Or anything that works for that matter. . This builds on work done by my colleague Andrew Freebairn, which really gave me a leg up. . Web API: which one? . I am not a regular user of online data. Whenever I really needed to fetch data from an online service, this tended to be an experience where reverting back to using a Web GUI with a &quot;download data&quot; button the path of least pain. . Before writing this section I got confused, trying to use kiwis-pie to retrieve data from the VIC data web site. Which is not suitable. I thought all Kisters products would be accessible using a unified web API. But Hydstra has its own separate from WIKSI, so far as I understand. See https://kisters.com.au/webservices.html . Curiously what seems to be the documentation for the Json API to Hydstra is in a page named HYDLLP – Flat DLL Interface to Hydstra. The examples are given in Perl, which is, well, not all that mainstream anymore. . There are visibly data codes to identify the types of data, at least to retrieve time series data. Query parameters such as varfrom and varto are kind of odd in an API though, and would deserve an explanation. It is only after manually downloading a time series from the VIC water data GUI that there is an explanation note about these variable codes. . The VIC data web site offers a way to directly link to URLs for particular data, but this seems not to work when used: https://data.water.vic.gov.au?ppbm=405288|B_405_GOULBURN|WEB_SW&amp;rs&amp;1&amp;rsdf_org . rdmw.qld.gov.au providing documentation for how to build json queries. . import requests import json import urllib import pandas as pd from datetime import date from IPython.core.display import HTML from IPython.display import JSON . def vic_url_builder(json_p, query): endpoint = &#39;http://data.water.vic.gov.au/cgi/webservice.exe&#39; return f&quot;{endpoint}?{json.dumps(json_p)}&amp;{urllib.parse.urlencode(query)}&quot; . The site identifiers of interest are: . site_id_405284 = &#39;405284&#39; # SUNDAY CREEK @ MT DISAPPOINTMENT site_id_405288 = &#39;405288&#39; # SUNDAY CREEK @ MT DISAPPOINTMENT (US SUNDAY CK. STORAGE site_id_405287 = &#39;405287&#39; # WESTCOTT CREEK @ MT DISAPPOINTMENT US SUNDAY CK STORAGE site_id_405239 = &#39;405239&#39; # SUNDAY CREEK @ CLONBINANE . # This took me a bit of time to figure out how to extract cumecs. One has to figure out that the &#39;varfrom&#39; in the query parameter needs to bhe the river level in metres. var_code_level_metres = &#39;100&#39; # var_code_cumecs = &#39;140&#39; # cumecs var_code_mlpd = &#39;141&#39; # ML/Day ver = { &#39;ver&#39;: &#39;2.0&#39; } #station_list = &#39;405288&#39; # don&#39;t set as 1-element list though: fails... station_list = &#39;,&#39;.join([ site_id_405284, site_id_405288, site_id_405287, site_id_405239, ]) def dt_str(x): return x.strftime(&#39;%Y%m%d%H%M%S&#39;) get_ts = { &#39;function&#39;:&#39;get_ts_traces&#39;, &#39;version&#39;:&#39;2&#39;, &#39;params&#39;:{ &#39;site_list&#39;:station_list, &#39;datasource&#39;:&#39;A&#39;, # THere are other codes, but this one is the only that returned something so far I can see. &#39;varfrom&#39;:var_code_level_metres, &#39;varto&#39;:var_code_cumecs, &#39;start_time&#39;:&#39;20220101000000&#39;, &#39;end_time&#39;:&#39;20220529000000&#39;, &#39;interval&#39;:&#39;day&#39;, &#39;multiplier&#39;:&#39;1&#39;, &#39;data_type&#39;:&#39;mean&#39;, } } query = vic_url_builder(get_ts, ver) . response = requests.get(query) . if response.status_code == requests.codes.ok: print(&#39;Return Json&#39;) print(response.headers[&#39;content-type&#39;]) response_json = response.json() # for visualisation in a notebook (not sure about rendered in a blog?) JSON(response_json) . Return Json text/html . &lt;IPython.core.display.JSON object&gt; . type(response_json) . dict . traces = response_json[&#39;return&#39;][&#39;traces&#39;] len(traces) . 2 . We got only trace time series for 2 of the 4 sites. This is because these sites have no recent data, at least not for the preiod of interest. Fair enough. For instance 405284 SUNDAY CREEK @ MT DISAPPOINTMENT functioned from from 23/06/1981 to 05/07/1984 . traces[0].keys() . dict_keys([&#39;error_num&#39;, &#39;compressed&#39;, &#39;site_details&#39;, &#39;quality_codes&#39;, &#39;trace&#39;, &#39;varfrom_details&#39;, &#39;site&#39;, &#39;varto_details&#39;]) . traces[0][&#39;site&#39;] . &#39;405288&#39; . tr = traces[0] tr[&#39;quality_codes&#39;] . {&#39;255&#39;: &#39;&#39;, &#39;100&#39;: &#39;Irregular data, use with caution.&#39;, &#39;2&#39;: &#39;Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction&#39;} . traces[1][&#39;quality_codes&#39;] . {&#39;255&#39;: &#39;&#39;, &#39;150&#39;: &#39;Rating extrapolated above 1.5x maximum flow gauged.&#39;, &#39;149&#39;: &#39;Rating extrapolated 1.5 times the maximum flow gauged.&#39;, &#39;2&#39;: &#39;Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction&#39;} . So this has good quality data, and some missing data (255). I am a bit puzzled by the codes for ratings beyond the max flow gauge, but the value appears to be sometimes zero flows in the data. Odd. . After a bit of iterative discovery, a way to turn json data to pandas series: . import numpy as np def to_dt64(x): return pd.Timestamp(x).to_datetime64() def make_daily_time_series(tr): site_name = tr[&#39;site&#39;] y = pd.DataFrame(tr[&#39;trace&#39;]) y.v = pd.to_numeric(y.v) v = y.v.values q = y.q.values y.t = y.t.apply(str) v[q == 255] = np.nan index = y.t.apply(to_dt64).values ts = pd.Series(v, index=index, name=site_name) return ts . ts = make_daily_time_series(traces[0]) ts.plot(ylabel=&quot;m3/s&quot;, xlabel=&quot;Time&quot;, title = ts.name) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;405288&#39;}, xlabel=&#39;Time&#39;, ylabel=&#39;m3/s&#39;&gt; . ts = make_daily_time_series(traces[1]) ts.plot(ylabel=&quot;m3/s&quot;, xlabel=&quot;Time&quot;, title = ts.name) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;405287&#39;}, xlabel=&#39;Time&#39;, ylabel=&#39;m3/s&#39;&gt; . Related resources . Andrew Freebairn&#39;s python package &#39;bomwater&#39; .",
            "url": "https://jmp75.github.io/work-blog/jupyter/hydstra/2022/05/28/hydstra-rest-data.html",
            "relUrl": "/jupyter/hydstra/2022/05/28/hydstra-rest-data.html",
            "date": " • May 28, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jmp75.github.io/work-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jmp75.github.io/work-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}