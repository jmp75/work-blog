<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.20">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="J-M">
<meta name="dcterms.date" content="2022-06-13">
<meta name="description" content="Exploring the use of NLP to exploit geologic information. Trying to classify lithologies.">

<title>Lithology classification using Hugging Face, part 2 ‚Äì J-M‚Äôs ‚Äòlab notebook‚Äô</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-bb336a360afc1d7ae78ffae72a144868.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-516d19510a3495a2f5c04694115b7fde.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-dark-816ffc7d711b40eec17926d7a06ac7f2.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-574be25b5a7772c3a765cc8590e29d11.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">J-M‚Äôs ‚Äòlab notebook‚Äô</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jmp75"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/jmp_oz"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Lithology classification using Hugging Face, part 2</h1>
                  <div>
        <div class="description">
          Exploring the use of NLP to exploit geologic information. Trying to classify lithologies.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">hugging-face</div>
                <div class="quarto-category">NLP</div>
                <div class="quarto-category">lithology</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>J-M </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 13, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#about" id="toc-about" class="nav-link active" data-scroll-target="#about">About</a></li>
  <li><a href="#kernel-installation" id="toc-kernel-installation" class="nav-link" data-scroll-target="#kernel-installation">Kernel installation</a></li>
  <li><a href="#walkthrough" id="toc-walkthrough" class="nav-link" data-scroll-target="#walkthrough">Walkthrough</a>
  <ul class="collapse">
  <li><a href="#imbalanced-data-sets" id="toc-imbalanced-data-sets" class="nav-link" data-scroll-target="#imbalanced-data-sets">Imbalanced data sets</a></li>
  <li><a href="#subsetting" id="toc-subsetting" class="nav-link" data-scroll-target="#subsetting">Subsetting</a></li>
  <li><a href="#class-imbalance" id="toc-class-imbalance" class="nav-link" data-scroll-target="#class-imbalance">Class imbalance</a>
  <ul class="collapse">
  <li><a href="#resample-with-replacement" id="toc-resample-with-replacement" class="nav-link" data-scroll-target="#resample-with-replacement">Resample with replacement</a></li>
  <li><a href="#dealing-with-imbalanced-classes-with-weights" id="toc-dealing-with-imbalanced-classes-with-weights" class="nav-link" data-scroll-target="#dealing-with-imbalanced-classes-with-weights">Dealing with imbalanced classes with weights</a></li>
  </ul></li>
  <li><a href="#tokenisation" id="toc-tokenisation" class="nav-link" data-scroll-target="#tokenisation">Tokenisation</a>
  <ul class="collapse">
  <li><a href="#bump-on-the-road-download-operations-taking-too-long" id="toc-bump-on-the-road-download-operations-taking-too-long" class="nav-link" data-scroll-target="#bump-on-the-road-download-operations-taking-too-long">Bump on the road; download operations taking too long</a></li>
  </ul></li>
  <li><a href="#create-dataset-and-tokenisation" id="toc-create-dataset-and-tokenisation" class="nav-link" data-scroll-target="#create-dataset-and-tokenisation">Create dataset and tokenisation</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">Training?</a></li>
  </ul></li>
  <li><a href="#stocktake-and-conclusion" id="toc-stocktake-and-conclusion" class="nav-link" data-scroll-target="#stocktake-and-conclusion">Stocktake and conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">
<script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    toggleBodyColorPrimary();
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        disableStylesheet(primaryStylesheets)
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const darkModeDefault = false;
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>





<section id="about" class="level1">
<h1>About</h1>
<p>This is a continuation of <a href="https://jmp75.github.io/work-blog/hugging-face/nlp/lithology/2022/06/01/lithology-classification-hugging-face.html">Lithology classification using Hugging Face, part 1</a>.</p>
<p>We saw in the previous post that the Namoi lithology logs data had their primary (major) lithology mostly completed. A substantial proportion had the label <code>None</code> nevertheless, despite descriptions that looked like they would obviously lead to a categorisation. There were many labels, with a long-tailed frequency histogram.</p>
<p>The aim of this post is (was) to get a classification training happening.</p>
<p><strong>Spoiler alert: it won‚Äôt</strong>. Almost.</p>
<p>Rather than write a post after the fact pretending it was a totally smooth journey, the following walktrough <em>deliberately</em> keeps and highlights issues, albeit succinctly. <strong>Don‚Äôt</strong> jump to the conclusion that we will not get there eventually, or that Hugging Face is not good. When you adapt prior work to your own use case, you <strong>will</strong> likely stumble, so this post will make you feel in good company.</p>
</section>
<section id="kernel-installation" class="level1">
<h1>Kernel installation</h1>
<p>The previous post was about data exploration and used mostly facilities such as pandas, not any deep learning related material. This post will, so we need to install Hugging Face. I did bump into a couple of issues while trying to get an environment going. I will not give the full grubby details, but highlight upfront a couple of things:</p>
<ul>
<li>Do create a new dedicated conda environment for your work with Hugging Face, even if you already have an environment with e.g.&nbsp;pytorch you‚Äôd like to reuse.</li>
<li>The version 4.11.3 of HF <code>transformers</code> on the conda channel <code>huggingface</code>, at the time of writing, has a <a href="https://github.com/nlp-with-transformers/notebooks/issues/31">bug</a>. You should install the packages from the <code>conda-forge</code> channel.</li>
</ul>
<p>In a nutshell, for Linux:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="va">myenv</span><span class="op">=</span>hf</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> create <span class="at">-n</span> <span class="va">$myenv</span> python=3.9 <span class="at">-c</span> conda-forge</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> install <span class="at">-n</span> <span class="va">$myenv</span> <span class="at">--yes</span> ipykernel matplotlib sentencepiece scikit-learn <span class="at">-c</span> conda-forge</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> install <span class="at">-n</span> <span class="va">$myenv</span> <span class="at">--yes</span> pytorch=1.11 <span class="at">-c</span> pytorch <span class="at">-c</span> nvidia <span class="at">-c</span> conda-forge</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> install <span class="at">-n</span> <span class="va">$myenv</span> <span class="at">--yes</span> torchvision torchaudio <span class="at">-c</span> pytorch <span class="at">-c</span> nvidia <span class="at">-c</span> conda-forge</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> install <span class="at">-n</span> <span class="va">$myenv</span> <span class="at">--yes</span> <span class="at">-c</span> conda-forge datasets transformers</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate <span class="va">$myenv</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> ipykernel install <span class="at">--user</span> <span class="at">--name</span> <span class="va">$myenv</span> <span class="at">--display-name</span> <span class="st">"Hugging Face"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>and in Windows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bat code-with-copy"><code class="sourceCode dosbat"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="bu">set</span> <span class="va">myenv</span>=hf</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>mamba create <span class="at">-n</span> <span class="pp">%</span><span class="va">myenv</span><span class="pp">%</span> python=3.9 <span class="at">-c</span> conda<span class="at">-forge</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>mamba install <span class="at">-n</span> <span class="pp">%</span><span class="va">myenv</span><span class="pp">%</span> -<span class="at">-yes</span> ipykernel matplotlib sentencepiece scikit<span class="at">-learn</span> <span class="at">-c</span> conda<span class="at">-forge</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>mamba install <span class="at">-n</span> <span class="pp">%</span><span class="va">myenv</span><span class="pp">%</span> -<span class="at">-yes</span> pytorch=1.11 <span class="at">-c</span> pytorch <span class="at">-c</span> nvidia <span class="at">-c</span> conda<span class="at">-forge</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>mamba install <span class="at">-n</span> <span class="pp">%</span><span class="va">myenv</span><span class="pp">%</span> -<span class="at">-yes</span> torchvision torchaudio <span class="at">-c</span> pytorch <span class="at">-c</span> nvidia <span class="at">-c</span> conda<span class="at">-forge</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>mamba install <span class="at">-n</span> <span class="pp">%</span><span class="va">myenv</span><span class="pp">%</span> -<span class="at">-yes</span> <span class="at">-c</span> conda<span class="at">-forge</span> datasets transformers</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>conda activate <span class="pp">%</span><span class="va">myenv</span><span class="pp">%</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>python <span class="at">-m</span> ipykernel install -<span class="at">-user</span> -<span class="at">-name</span> <span class="pp">%</span><span class="va">myenv</span><span class="pp">%</span> -<span class="at">-display-name</span> <span class="st">"Hugging Face"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="walkthrough" class="level1">
<h1>Walkthrough</h1>
<p>Let‚Äôs get on with all the imports upfront (not obvious, mind you, but after the fact‚Ä¶)</p>
<div id="bab780c4-075b-4bd8-8882-677a5fe59c30" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification, AutoTokenizer</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> ClassLabel</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> TrainingArguments, Trainer</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Some column string identifiers</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>MAJOR_CODE <span class="op">=</span> <span class="st">"MajorLithCode"</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>MAJOR_CODE_INT <span class="op">=</span> <span class="st">"MajorLithoCodeInt"</span>  <span class="co"># We will create a numeric representation of labels, which is (I think?) required by HF.</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>MINOR_CODE <span class="op">=</span> <span class="st">"MinorLithCode"</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>DESC <span class="op">=</span> <span class="st">"Description"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/abcdef/miniconda/envs/hf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm</code></pre>
</div>
</div>
<div id="d636dc61-9628-4ad5-8e3d-559e2b7b82b2" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>fn <span class="op">=</span> Path(<span class="st">"~"</span>).expanduser() <span class="op">/</span> <span class="st">"data/ela/shp_namoi_river/NGIS_LithologyLog.csv"</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>litho_logs <span class="op">=</span> pd.read_csv(</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    fn, dtype<span class="op">=</span>{<span class="st">"FromDepth"</span>: <span class="bu">str</span>, <span class="st">"ToDepth"</span>: <span class="bu">str</span>, MAJOR_CODE: <span class="bu">str</span>, MINOR_CODE: <span class="bu">str</span>}</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># To avoid importing from the ela package, copy a couple of functions:</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># from ela.textproc import token_freq, plot_freq</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> token_freq(tokens, n_most_common<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    list_most_common <span class="op">=</span> Counter(tokens).most_common(n_most_common)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(list_most_common, columns<span class="op">=</span>[<span class="st">"token"</span>, <span class="st">"frequency"</span>])</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_freq(dataframe, y_log<span class="op">=</span><span class="va">False</span>, x<span class="op">=</span><span class="st">"token"</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>), fontsize<span class="op">=</span><span class="dv">14</span>):</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Plot a sorted histogram of work frequencies</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co">        dataframe (pandas dataframe): frequency of tokens, typically with colnames ["token","frequency"]</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co">        y_log (bool): should there be a log scale on the y axis</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co">        x (str): name of the columns with the tokens (i.e. words)</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co">        figsize (tuple):</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co">        fontsize (int):</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co">        barplot: plot</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> dataframe.plot.bar(x<span class="op">=</span>x, figsize<span class="op">=</span>figsize, fontsize<span class="op">=</span>fontsize)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> y_log:</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        p.set_yscale(<span class="st">"log"</span>, nonposy<span class="op">=</span><span class="st">"clip"</span>)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> p</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>litho_classes <span class="op">=</span> litho_logs[MAJOR_CODE].values</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>df_most_common <span class="op">=</span> token_freq(litho_classes, <span class="dv">50</span>)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>plot_freq(df_most_common)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-06-13-lithology-classification-hugging-face-2_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="imbalanced-data-sets" class="level2">
<h2 class="anchored" data-anchor-id="imbalanced-data-sets">Imbalanced data sets</h2>
<p>From the histogram above, it is pretty clear that labels are also not uniform an we have a class imbalance. Remember to skim <a href="https://jmp75.github.io/work-blog/hugging-face/nlp/lithology/2022/06/01/lithology-classification-hugging-face.html">Lithology classification using Hugging Face, part 1</a> for the initial data exploration if you have not done so already.</p>
<p>For the sake of the exercise in this post, I will reduce arbitrarily the number of labels used in this post, by just ‚Äúforgetting‚Äù the less represented classes.</p>
<p>There are many resources about class imbalances. One of them is <a href="https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset">8 Tactics to combat imbalanced classes in your machine learning dataset</a></p>
<p>Let‚Äôs see what labels we may want to keep for this post:</p>
<div id="14539625-66ca-4ec7-971e-73859f5aa579" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_desc_for_code(major_code, n<span class="op">=</span><span class="dv">50</span>, seed<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    is_code <span class="op">=</span> litho_logs[MAJOR_CODE] <span class="op">==</span> major_code</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    coded <span class="op">=</span> litho_logs.loc[is_code][DESC]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> seed <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        np.random.seed(seed)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> coded.sample(n<span class="op">=</span><span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="2341f6d3-3216-4223-9428-41aad2ff098e" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>sample_desc_for_code(<span class="st">"UNKN"</span>, seed<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>134145     (UNKNOWN), NO SAMPLE COLLECTED DUE TO WATER LOSS
134715    (UNKNOWN); COULD NOT BE LOGGED BECAUSE NO CUTT...
122303                                          GREY SHALEY
133856                                              NOMINAL
134378                                                 None
133542                                              DRILLER
122258                                        WATER BEARING
127916                                         WATER SUPPLY
133676                                              DRILLER
134399                                              DRILLER
134052                                              DRILLER
128031                         VERY SANDY STONES SOME LARGE
134140                                       SAMPLE MISSING
122282                              REDDISH YELLOW VOLCANIC
133623                                    WHITE CRYSTALLINE
134505                                              MISSING
133694                                              DRILLER
133585                                              DRILLER
134201                                              MISSING
134627                                              NO DATA
133816                                              DRILLER
133893                                              DRILLER
134232                                              DRILLER
133687                                              DRILLER
133871                                              DRILLER
133698                                              DRILLER
134752                                              MISSING
128077                           WATER BEARING WATER SUPPLY
122253                                         WATER SUPPLY
133607                                              DRILLER
133617                                              DRILLER
133643                                                 HARD
134526                                  (UNKNOWN) CORE LOSS
133709                                        SANDY STREAKS
123254                                 NOMINAL WATER SUPPLY
122219                                         WATER SUPPLY
133525                                              DRILLER
127799                                         WATER SUPPLY
133940                                              DRILLER
124775                              (UNKNOWN) WATER BEARING
126814                             (UNKNOWN); WATER BEARING
133965                                              DRILLER
134074                                              DRILLER
134395                                              DRILLER
133970                                              DRILLER
134262                                              DRILLER
122407                                         WATER SUPPLY
144370                                            S/S LT BR
125023                             (UNKNOWN); WATER BEARING
133675                                              DRILLER
Name: Description, dtype: object</code></pre>
</div>
</div>
<p>The ‚Äúunknown‚Äù category is rather interesting in fact, and worth keeping as a valid class.</p>
</section>
<section id="subsetting" class="level2">
<h2 class="anchored" data-anchor-id="subsetting">Subsetting</h2>
<p>Let‚Äôs keep ‚Äúonly‚Äù the main labels, for the sake of this exercise. We will remove None however, despite its potential interest. We will (hopefully) revisit this in another post.</p>
<div id="ed9845e0-dd92-435c-b3df-9117254ca549" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>labels_kept <span class="op">=</span> df_most_common[<span class="st">"token"</span>][:<span class="dv">17</span>].values  <span class="co"># 17 first classes somewhat arbitraty</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>labels_kept <span class="op">=</span> labels_kept[labels_kept <span class="op">!=</span> <span class="st">"None"</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>labels_kept</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>array(['CLAY', 'GRVL', 'SAND', 'SHLE', 'SDSN', 'BSLT', 'TPSL', 'SOIL',
       'ROCK', 'GRNT', 'SDCY', 'SLSN', 'CGLM', 'MDSN', 'UNKN', 'COAL'],
      dtype=object)</code></pre>
</div>
</div>
<div id="2eeca839" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>kept <span class="op">=</span> [x <span class="kw">in</span> labels_kept <span class="cf">for</span> x <span class="kw">in</span> litho_classes]</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>litho_logs_kept <span class="op">=</span> litho_logs[kept].copy()  <span class="co"># avoid warning messages down the track.</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>litho_logs_kept.sample(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">OBJECTID</th>
<th data-quarto-table-cell-role="th">BoreID</th>
<th data-quarto-table-cell-role="th">HydroCode</th>
<th data-quarto-table-cell-role="th">RefElev</th>
<th data-quarto-table-cell-role="th">RefElevDesc</th>
<th data-quarto-table-cell-role="th">FromDepth</th>
<th data-quarto-table-cell-role="th">ToDepth</th>
<th data-quarto-table-cell-role="th">TopElev</th>
<th data-quarto-table-cell-role="th">BottomElev</th>
<th data-quarto-table-cell-role="th">MajorLithCode</th>
<th data-quarto-table-cell-role="th">MinorLithCode</th>
<th data-quarto-table-cell-role="th">Description</th>
<th data-quarto-table-cell-role="th">Source</th>
<th data-quarto-table-cell-role="th">LogType</th>
<th data-quarto-table-cell-role="th">OgcFidTemp</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">70655</td>
<td>526412</td>
<td>10072593</td>
<td>GW031851.1.1</td>
<td>None</td>
<td>UNK</td>
<td>53.94</td>
<td>59.13</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY SANDY</td>
<td>UNK</td>
<td>1</td>
<td>9308381</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7173</td>
<td>64072</td>
<td>10043001</td>
<td>GW001815.1.1</td>
<td>None</td>
<td>UNK</td>
<td>31.39</td>
<td>44.5</td>
<td>None</td>
<td>None</td>
<td>SHLE</td>
<td>NaN</td>
<td>SHALE</td>
<td>UNK</td>
<td>1</td>
<td>8732384</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">30076</td>
<td>197788</td>
<td>10152523</td>
<td>GW099036.1.1</td>
<td>None</td>
<td>UNK</td>
<td>181.0</td>
<td>228.0</td>
<td>None</td>
<td>None</td>
<td>SHLE</td>
<td>NaN</td>
<td>SHALE: GREY, FINE</td>
<td>UNK</td>
<td>1</td>
<td>8870150</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">93967</td>
<td>701859</td>
<td>10105392</td>
<td>GW031140.1.1</td>
<td>None</td>
<td>UNK</td>
<td>0.0</td>
<td>8.84</td>
<td>None</td>
<td>None</td>
<td>SOIL</td>
<td>NaN</td>
<td>SOIL CLAY</td>
<td>UNK</td>
<td>1</td>
<td>9327759</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">115538</td>
<td>803595</td>
<td>10099300</td>
<td>GW970770.1.1</td>
<td>None</td>
<td>UNK</td>
<td>36.6</td>
<td>38.1</td>
<td>None</td>
<td>None</td>
<td>SAND</td>
<td>NaN</td>
<td>SAND; FINE TO COARSE, BROWN</td>
<td>UNK</td>
<td>1</td>
<td>9435886</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">107173</td>
<td>762000</td>
<td>10122945</td>
<td>GW018629.1.1</td>
<td>None</td>
<td>UNK</td>
<td>72.54</td>
<td>74.37</td>
<td>None</td>
<td>None</td>
<td>SDSN</td>
<td>NaN</td>
<td>SANDSTONE YELLOW HARD</td>
<td>UNK</td>
<td>1</td>
<td>9389679</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">106769</td>
<td>760370</td>
<td>10111007</td>
<td>GW026576.1.1</td>
<td>None</td>
<td>UNK</td>
<td>65.23</td>
<td>71.32</td>
<td>None</td>
<td>None</td>
<td>SDSN</td>
<td>NaN</td>
<td>SANDSTONE WATER SUPPLY</td>
<td>UNK</td>
<td>1</td>
<td>9388007</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13553</td>
<td>114744</td>
<td>10116235</td>
<td>GW022175.1.1</td>
<td>None</td>
<td>UNK</td>
<td>37.8</td>
<td>39.01</td>
<td>None</td>
<td>None</td>
<td>GRVL</td>
<td>NaN</td>
<td>GRAVEL FINE-COARSE</td>
<td>UNK</td>
<td>1</td>
<td>8784472</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">142398</td>
<td>971715</td>
<td>10074454</td>
<td>GW901230.1.1</td>
<td>None</td>
<td>UNK</td>
<td>20.0</td>
<td>24.0</td>
<td>None</td>
<td>None</td>
<td>GRVL</td>
<td>NaN</td>
<td>GRAVEL</td>
<td>UNK</td>
<td>1</td>
<td>9567221</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9664</td>
<td>85061</td>
<td>10043586</td>
<td>GW011521.1.1</td>
<td>None</td>
<td>UNK</td>
<td>12.19</td>
<td>20.73</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY YELLOW GRAVEL</td>
<td>UNK</td>
<td>1</td>
<td>8753973</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="770b0665-1158-478f-ab2c-3bbb753f363d" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> ClassLabel(names<span class="op">=</span>labels_kept)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>int_labels <span class="op">=</span> np.array([</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    labels.str2int(x) <span class="cf">for</span> x <span class="kw">in</span> litho_logs_kept[MAJOR_CODE].values</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>int_labels <span class="op">=</span> int_labels.astype(np.int8) <span class="co"># to mimick chapter3 HF so far as I can see</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="31a836a8-f4c0-4fad-970d-081936a2181b" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>litho_logs_kept[MAJOR_CODE_INT] <span class="op">=</span> int_labels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="class-imbalance" class="level2">
<h2 class="anchored" data-anchor-id="class-imbalance">Class imbalance</h2>
<p>Even our subset of 16 classes is rather imbalanced; the number of ‚Äúclay‚Äù labels is looking more than 30 times that of ‚Äúcoal‚Äù just by eyeballing.</p>
<p>The post by Jason Brownlee <a href="https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset">8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset</a>, outlines several approaches. One of them is to resample from labels, perhaps with replacement, to equalise classes. It is a relatively easy approach to implement, but there are issues, growing with the level of imbalance. Notably, if too many rows from underrepresented classes are repeated, there is an increased tendency to overfitting at training.</p>
<p>The video <a href="https://youtu.be/u--UVvH-LIQ?t=669">Simple Training with the ü§ó Transformers Trainer (at 669 seconds)</a> also explains the issues with imbalances and crude resampling. It offers instead a solution with class weighting that is more robust. That approach is evoked in Jason‚Äôs post, but the video has a ‚ÄúHugging Face style‚Äù implementation ready to repurpose.</p>
<section id="resample-with-replacement" class="level3">
<h3 class="anchored" data-anchor-id="resample-with-replacement">Resample with replacement</h3>
<p>Just for information, what we‚Äôd do with a relatively crude resampling may be:</p>
<div id="6b1b392e" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_major_lithocode(dframe, code, n<span class="op">=</span><span class="dv">10000</span>, seed<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> dframe[dframe[MAJOR_CODE] <span class="op">==</span> code]</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    replace <span class="op">=</span> n <span class="op">&gt;</span> <span class="bu">len</span>(x)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x.sample(n<span class="op">=</span>n, replace<span class="op">=</span>replace, random_state<span class="op">=</span>seed)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="4f04f51e" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>sample_major_lithocode(litho_logs_kept, <span class="st">"CLAY"</span>, n<span class="op">=</span><span class="dv">10</span>, seed<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">OBJECTID</th>
<th data-quarto-table-cell-role="th">BoreID</th>
<th data-quarto-table-cell-role="th">HydroCode</th>
<th data-quarto-table-cell-role="th">RefElev</th>
<th data-quarto-table-cell-role="th">RefElevDesc</th>
<th data-quarto-table-cell-role="th">FromDepth</th>
<th data-quarto-table-cell-role="th">ToDepth</th>
<th data-quarto-table-cell-role="th">TopElev</th>
<th data-quarto-table-cell-role="th">BottomElev</th>
<th data-quarto-table-cell-role="th">MajorLithCode</th>
<th data-quarto-table-cell-role="th">MinorLithCode</th>
<th data-quarto-table-cell-role="th">Description</th>
<th data-quarto-table-cell-role="th">Source</th>
<th data-quarto-table-cell-role="th">LogType</th>
<th data-quarto-table-cell-role="th">OgcFidTemp</th>
<th data-quarto-table-cell-role="th">MajorLithoCodeInt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">106742</td>
<td>760246</td>
<td>10144429</td>
<td>GW030307.1.1</td>
<td>279.5</td>
<td>NGS</td>
<td>54.3</td>
<td>72.2</td>
<td>225.2</td>
<td>207.3</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY LIGHT BROWN GRAVEL</td>
<td>UNK</td>
<td>1</td>
<td>9387877</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">138850</td>
<td>950521</td>
<td>10147004</td>
<td>GW036015.2.2</td>
<td>236.0</td>
<td>NGS</td>
<td>73.15</td>
<td>74.676</td>
<td>162.85</td>
<td>161.324</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY; AS ABOVE, MORE MICACEOUS &amp; FINE GRAVEL (...</td>
<td>?? - WC&amp;IC</td>
<td>2</td>
<td>9543085</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">30006</td>
<td>197243</td>
<td>10049338</td>
<td>GW062392.1.1</td>
<td>None</td>
<td>UNK</td>
<td>63.0</td>
<td>64.0</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY SANDY</td>
<td>UNK</td>
<td>1</td>
<td>8869540</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3225</td>
<td>29304</td>
<td>10142901</td>
<td>GW014623.1.1</td>
<td>None</td>
<td>UNK</td>
<td>22.86</td>
<td>23.47</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY SANDY</td>
<td>UNK</td>
<td>1</td>
<td>8696556</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9795</td>
<td>86262</td>
<td>10121680</td>
<td>GW009977.1.1</td>
<td>None</td>
<td>UNK</td>
<td>39.01</td>
<td>42.67</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY YELLOW PUGGY</td>
<td>UNK</td>
<td>1</td>
<td>8755205</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">49588</td>
<td>427460</td>
<td>10067562</td>
<td>GW964964.1.1</td>
<td>None</td>
<td>UNK</td>
<td>11.0</td>
<td>14.0</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY</td>
<td>UNK</td>
<td>1</td>
<td>9199868</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">136116</td>
<td>943202</td>
<td>10055892</td>
<td>GW971627.1.1</td>
<td>None</td>
<td>UNK</td>
<td>14.0</td>
<td>20.0</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>GREY WET CLAY</td>
<td>UNK</td>
<td>1</td>
<td>9534634</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5723</td>
<td>50788</td>
<td>10049974</td>
<td>GW010017.1.1</td>
<td>None</td>
<td>UNK</td>
<td>14.02</td>
<td>24.38</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY RED SANDY</td>
<td>UNK</td>
<td>1</td>
<td>8718677</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">94938</td>
<td>706287</td>
<td>10018922</td>
<td>GW022845.1.1</td>
<td>None</td>
<td>UNK</td>
<td>1.22</td>
<td>11.58</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY</td>
<td>UNK</td>
<td>1</td>
<td>9332267</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">38277</td>
<td>287347</td>
<td>10132392</td>
<td>GW042735.1.1</td>
<td>None</td>
<td>UNK</td>
<td>0.75</td>
<td>6.0</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY</td>
<td>UNK</td>
<td>1</td>
<td>8942094</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="277c7c1c-d26d-4ac8-acb7-466fd68fae0c" class="cell" data-tags="[]" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>balanced_litho_logs <span class="op">=</span> [</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    sample_major_lithocode(litho_logs_kept, code, n<span class="op">=</span><span class="dv">10000</span>, seed<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> code <span class="kw">in</span> labels_kept</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>balanced_litho_logs <span class="op">=</span> pd.concat(balanced_litho_logs)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>balanced_litho_logs.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">OBJECTID</th>
<th data-quarto-table-cell-role="th">BoreID</th>
<th data-quarto-table-cell-role="th">HydroCode</th>
<th data-quarto-table-cell-role="th">RefElev</th>
<th data-quarto-table-cell-role="th">RefElevDesc</th>
<th data-quarto-table-cell-role="th">FromDepth</th>
<th data-quarto-table-cell-role="th">ToDepth</th>
<th data-quarto-table-cell-role="th">TopElev</th>
<th data-quarto-table-cell-role="th">BottomElev</th>
<th data-quarto-table-cell-role="th">MajorLithCode</th>
<th data-quarto-table-cell-role="th">MinorLithCode</th>
<th data-quarto-table-cell-role="th">Description</th>
<th data-quarto-table-cell-role="th">Source</th>
<th data-quarto-table-cell-role="th">LogType</th>
<th data-quarto-table-cell-role="th">OgcFidTemp</th>
<th data-quarto-table-cell-role="th">MajorLithoCodeInt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">106742</td>
<td>760246</td>
<td>10144429</td>
<td>GW030307.1.1</td>
<td>279.5</td>
<td>NGS</td>
<td>54.3</td>
<td>72.2</td>
<td>225.2</td>
<td>207.3</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY LIGHT BROWN GRAVEL</td>
<td>UNK</td>
<td>1</td>
<td>9387877</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">138850</td>
<td>950521</td>
<td>10147004</td>
<td>GW036015.2.2</td>
<td>236.0</td>
<td>NGS</td>
<td>73.15</td>
<td>74.676</td>
<td>162.85</td>
<td>161.324</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY; AS ABOVE, MORE MICACEOUS &amp; FINE GRAVEL (...</td>
<td>?? - WC&amp;IC</td>
<td>2</td>
<td>9543085</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">30006</td>
<td>197243</td>
<td>10049338</td>
<td>GW062392.1.1</td>
<td>None</td>
<td>UNK</td>
<td>63.0</td>
<td>64.0</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY SANDY</td>
<td>UNK</td>
<td>1</td>
<td>8869540</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3225</td>
<td>29304</td>
<td>10142901</td>
<td>GW014623.1.1</td>
<td>None</td>
<td>UNK</td>
<td>22.86</td>
<td>23.47</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY SANDY</td>
<td>UNK</td>
<td>1</td>
<td>8696556</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9795</td>
<td>86262</td>
<td>10121680</td>
<td>GW009977.1.1</td>
<td>None</td>
<td>UNK</td>
<td>39.01</td>
<td>42.67</td>
<td>None</td>
<td>None</td>
<td>CLAY</td>
<td>NaN</td>
<td>CLAY YELLOW PUGGY</td>
<td>UNK</td>
<td>1</td>
<td>8755205</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="77d079a6" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>plot_freq(token_freq(balanced_litho_logs[MAJOR_CODE].values, <span class="dv">50</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2022-06-13-lithology-classification-hugging-face-2_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="dealing-with-imbalanced-classes-with-weights" class="level3">
<h3 class="anchored" data-anchor-id="dealing-with-imbalanced-classes-with-weights">Dealing with imbalanced classes with weights</h3>
<p>Instead of the resampling above, we adapt the approach creating weights for the Trainer we will run.</p>
<div id="ba803906-962a-45b5-beb7-3293b30e0a9a" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>sorted_counts <span class="op">=</span> litho_logs_kept[MAJOR_CODE].value_counts()</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>sorted_counts</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>CLAY    43526
GRVL    15824
SAND    15317
SHLE    10158
SDSN     9199
BSLT     7894
TPSL     5300
SOIL     4347
ROCK     2549
GRNT     1852
SDCY     1643
SLSN     1443
CGLM     1233
MDSN     1207
UNKN     1125
COAL     1040
Name: MajorLithCode, dtype: int64</code></pre>
</div>
</div>
<div id="61a0c271-e04b-4a10-89cf-b175bcab4c09" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>sorted_counts <span class="op">/</span> sorted_counts.<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>CLAY    0.351990
GRVL    0.127967
SAND    0.123867
SHLE    0.082147
SDSN    0.074391
BSLT    0.063838
TPSL    0.042860
SOIL    0.035154
ROCK    0.020613
GRNT    0.014977
SDCY    0.013287
SLSN    0.011669
CGLM    0.009971
MDSN    0.009761
UNKN    0.009098
COAL    0.008410
Name: MajorLithCode, dtype: float64</code></pre>
</div>
</div>
<div id="085e9d3f-7a35-4f93-8371-3e5b883b8536" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>class_weights <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> sorted_counts <span class="op">/</span> sorted_counts.<span class="bu">sum</span>()).values</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>class_weights</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>array([0.64801022, 0.87203312, 0.87613317, 0.91785342, 0.92560874,
       0.93616213, 0.95713951, 0.96484631, 0.97938653, 0.98502309,
       0.98671325, 0.98833062, 0.99002887, 0.99023913, 0.99090225,
       0.99158964])</code></pre>
</div>
</div>
<p>We check that cuda is available (of course optional)</p>
<div id="cc787f1f-882e-46d4-9a51-95c7b0396b0c" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> torch.cuda.is_available()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>On Linux if you have a DELL laptop with an NVIDIA card, but <code>nvidia-smi</code> returns: <code>NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running</code>, you may need to change your kernel specification file $HOME/.local/share/jupyter/kernels/hf/kernel.json. This behavior seems to depend on the version of Linux kernel you have. It certainly changed out of the blue for me from yesterday, despite no change that I can tell.</p>
<p><code>optirun nvidia-smi</code> returning a proper graphic card report should be a telltale sign you have to update your kernel.json like so:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a> <span class="dt">"argv"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"optirun"</span><span class="ot">,</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"/home/your_ident/miniconda/envs/hf/bin/python"</span><span class="ot">,</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"-m"</span><span class="ot">,</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">"ipykernel_launcher"</span><span class="ot">,</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">"-f"</span><span class="ot">,</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">"{connection_file}"</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a> <span class="ot">]</span><span class="fu">,</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a> <span class="dt">"display_name"</span><span class="fu">:</span> <span class="st">"Hugging Face"</span><span class="fu">,</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a> <span class="dt">"language"</span><span class="fu">:</span> <span class="st">"python"</span><span class="fu">,</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a> <span class="dt">"metadata"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"debugger"</span><span class="fu">:</span> <span class="kw">true</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a> <span class="fu">}</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You may need to restart jupyter-lab, or visual studio code, etc., for change to take effect. Restarting the kernel may not be enough, conter-intuitively.</p>
<p>Background details about optirun architecture at [Bumblebee Debian]https://wiki.debian.org/Bumblebee</p>
<div id="06c1451d-db34-4335-9db3-0745f1e859c5" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>class_weights <span class="op">=</span> torch.from_numpy(class_weights).<span class="bu">float</span>().to(<span class="st">"cuda"</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>class_weights</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([0.6480, 0.8720, 0.8761, 0.9179, 0.9256, 0.9362, 0.9571, 0.9648, 0.9794,
        0.9850, 0.9867, 0.9883, 0.9900, 0.9902, 0.9909, 0.9916],
       device='cuda:0')</code></pre>
</div>
</div>
<div id="533be356" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>model_nm <span class="op">=</span> <span class="st">"microsoft/deberta-v3-small"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="tokenisation" class="level2">
<h2 class="anchored" data-anchor-id="tokenisation">Tokenisation</h2>
<section id="bump-on-the-road-download-operations-taking-too-long" class="level3">
<h3 class="anchored" data-anchor-id="bump-on-the-road-download-operations-taking-too-long">Bump on the road; download operations taking too long</h3>
<p>At this point I spent more hours than I wish I had on an issue, perhaps very unusual.</p>
<p>The operation <code>tokz = AutoTokenizer.from_pretrained(model_nm)</code> was taking an awful long time to complete:</p>
<pre class="text"><code>CPU times: user 504 ms, sys: 57.9 ms, total: 562 ms
Wall time: 14min 13s</code></pre>
<p>To cut a long story short, I managed to figure out what was going on. It is documented on the Hugging Face forum at: <a href="https://discuss.huggingface.co/t/some-hf-operations-take-an-excessively-long-time-to-complete/18986">Some HF operations take an excessively long time to complete</a>. If you have issues where HF operations take a long time, read it.</p>
<p>Now back to the tokenisation story. Note that the local caching may be superflous if you do not encounter the issue just mentioned.</p>
<div id="9fa5cae0-5732-408c-90f7-4d668a810889" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>max_length <span class="op">=</span> <span class="dv">128</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0ffcb883-d2c9-405f-a448-e0688efa9efd" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> Path(<span class="st">"./tokz_pretrained"</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>pretrained_model_name_or_path <span class="op">=</span> p <span class="cf">if</span> p.exists() <span class="cf">else</span> model_nm</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co"># https://discuss.huggingface.co/t/sentence-transformers-paraphrase-minilm-fine-tuning-error/9612/4</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>tokz <span class="op">=</span> AutoTokenizer.from_pretrained(pretrained_model_name_or_path, use_fast<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span>max_length, model_max_length<span class="op">=</span>max_length)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> p.exists():</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    tokz.save_pretrained(<span class="st">"./tokz_pretrained"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let‚Äôs see what this does on a typical lithology description</p>
<div id="c65ccaab" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>tokz.tokenize(<span class="st">"CLAY, VERY SANDY"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>['‚ñÅC', 'LAY', ',', '‚ñÅVERY', '‚ñÅS', 'ANDY']</code></pre>
</div>
</div>
<p>Well, the vocabulary is probably case sensitive and all the descriptions being uppercase in the source data are likely problematic. Let‚Äôs check what happens on lowercase descriptions:</p>
<div id="d2b977ef" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>tokz.tokenize(<span class="st">"clay, very sandy"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>['‚ñÅclay', ',', '‚ñÅvery', '‚ñÅsandy']</code></pre>
</div>
</div>
<p>This looks better. So let‚Äôs change the descriptions to lowercase; we are not loosing any relevent information in this case, I think.</p>
<div id="4bd22306" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># note: no warnings because we used .copy() earlier to create litho_logs_kept</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>litho_logs_kept[DESC] <span class="op">=</span> litho_logs_kept[DESC].<span class="bu">str</span>.lower()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="bf5876f5" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>litho_logs_kept_mini <span class="op">=</span> litho_logs_kept[[MAJOR_CODE_INT, DESC]]</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>litho_logs_kept_mini.sample(n<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">MajorLithoCodeInt</th>
<th data-quarto-table-cell-role="th">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">8256</td>
<td>5</td>
<td>basalt</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">96820</td>
<td>4</td>
<td>sandstone</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">36776</td>
<td>2</td>
<td>sand</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">110231</td>
<td>0</td>
<td>clay; light brown, very silty</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">80270</td>
<td>1</td>
<td>gravel &amp; large stones</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17592</td>
<td>1</td>
<td>gravel water supply</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">74437</td>
<td>0</td>
<td>clay</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">22904</td>
<td>5</td>
<td>basalt stones</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">71578</td>
<td>1</td>
<td>gravel very clayey water supply</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">73030</td>
<td>3</td>
<td>shale</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="create-dataset-and-tokenisation" class="level2">
<h2 class="anchored" data-anchor-id="create-dataset-and-tokenisation">Create dataset and tokenisation</h2>
<p>We want to create a dataset such that tokenised data is of uniform shape (better for running on GPU) Applying the technique in <a href="https://youtu.be/_BZearw7f0w?list=PLo2EIpI_JMQvWfQndUesu0nPBAtZ9gP1o&amp;t=150">this segment of the HF course video</a>. Cheating a bit on guessing the length (I know from offline checks that max is 90 tokens)</p>
<div id="57c6cb10-d14f-4ec0-8068-ac96fe3ae7b1" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>ds <span class="op">=</span> Dataset.from_pandas(litho_logs_kept_mini)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tok_func(x):</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokz(</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>        x[DESC],</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">"max_length"</span>,</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>max_length,</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>        return_tensors<span class="op">=</span><span class="st">"pt"</span>,</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The Youtube video above suggests to use <code>tok_ds = ds.map(tok_func, batched=True)</code> for a faster execution; however I ended up with the foollowing error:</p>
<pre class="text"><code>TypeError: Provided `function` which is applied to all elements of table returns a `dict` of types [&lt;class 'torch.Tensor'&gt;, &lt;class 'torch.Tensor'&gt;, &lt;class 'torch.Tensor'&gt;]. When using `batched=True`, make sure provided `function` returns a `dict` of types like `(&lt;class 'list'&gt;, &lt;class 'numpy.ndarray'&gt;)`.</code></pre>
<p>The following non-batched option works in a reasonable time:</p>
<div id="cae491a9-4934-4703-8ce0-b29024d1804a" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>tok_ds <span class="op">=</span> ds.<span class="bu">map</span>(tok_func)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Parameter 'function'=&lt;function tok_func at 0x7f0d047695e0&gt; of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123657/123657 [00:24&lt;00:00, 4962.06ex/s]</code></pre>
</div>
</div>
<div id="0a5b8730" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>tok_ds_tmp <span class="op">=</span> tok_ds[:<span class="dv">5</span>]</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>tok_ds_tmp.keys()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>dict_keys(['MajorLithoCodeInt', 'Description', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'])</code></pre>
</div>
</div>
<div id="0e9412e8" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check the length of vectors is indeed 128:</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(tok_ds_tmp[<span class="st">"input_ids"</span>][<span class="dv">0</span>][<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>128</code></pre>
</div>
</div>
<div id="000feb4d-7a37-4aa3-85b4-e28f562465d0" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>num_labels <span class="op">=</span> <span class="bu">len</span>(labels_kept)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c78fa880-3100-492e-ac22-ea8b54420389" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">NOTE</span><span class="co">: the local caching may be superflous</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> Path(<span class="st">"./model_pretrained"</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> p <span class="cf">if</span> p.exists() <span class="cf">else</span> model_nm</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_name, num_labels<span class="op">=</span>num_labels, max_length<span class="op">=</span>max_length)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>                                                           <span class="co"># label2id=label2id, id2label=id2label).to(device) </span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> p.exists():</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>    model.save_pretrained(p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="ce1d88f6" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'transformers.models.deberta_v2.modeling_deberta_v2.DebertaV2ForSequenceClassification'&gt;</code></pre>
</div>
</div>
<div id="3c718455" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Different approach, but one that I am not sure how to progress to a hugging face Dataset. Borrowed from [this video](https://youtu.be/1pedAIvTWXk?list=PLo2EIpI_JMQvWfQndUesu0nPBAtZ9gP1o&amp;t=143)</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co"># litho_desc_list = [x for x in litho_logs_kept_mini[DESC].values]</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="co"># input_descriptions = tokz(litho_desc_list, padding=True, truncation=True, max_length=256, return_tensors='pt')</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co"># input_descriptions['input_ids'].shape</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co"># model(input_descriptions['input_ids'][:5,:], attention_mask=input_descriptions['attention_mask'][:5,:]).logits</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b9e9e2d1-eb58-4053-b220-057d134f05d2" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>tok_ds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>Dataset({
    features: ['MajorLithoCodeInt', 'Description', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],
    num_rows: 123657
})</code></pre>
</div>
</div>
<p>Transformers always assumes that your labels has the column name ‚Äúlabels‚Äù. Odd, but at least this fosters a consistent system, so why not:</p>
<div id="96641167-e9a7-4317-8b6b-4f077e39254e" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>tok_ds <span class="op">=</span> tok_ds.rename_columns({MAJOR_CODE_INT: <span class="st">"labels"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="449b2ff0-88d1-45d0-9c44-98379c090edc" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>tok_ds <span class="op">=</span> tok_ds.remove_columns([<span class="st">'Description'</span>, <span class="st">'__index_level_0__'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0779474c" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We want to make sure we work on the GPU, so at least make sure we have torch tensors.</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that HF is supposed to take care of movind data to the GPU if available, so you should not ahve to manually copy the data to the GPU device</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>tok_ds.set_format(<span class="st">"torch"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="db834a45-676a-4d1e-9da7-bff9d98d6243" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># args = TrainingArguments(output_dir='./litho_outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="co">#     evaluation_strategy="epoch", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="co">#     num_train_epochs=epochs, weight_decay=0.01, report_to='none')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="802eac87-b5ce-41d2-8b4c-8bd4d0e4337d" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>dds <span class="op">=</span> tok_ds.train_test_split(<span class="fl">0.25</span>, seed<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="7c8b2de4-2ba6-47b0-a89b-44ddcc352300" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>dds.keys()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>dict_keys(['train', 'test'])</code></pre>
</div>
</div>
<div id="b1ed9503-ea52-46a2-a7d9-408f1eead194" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>tok_ds.features[<span class="st">'labels'</span>] <span class="op">=</span> labels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c522fbd9-6c98-4c96-b95b-c393f6b4cb72" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>tok_ds.features</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">:</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co">#     This differs from chapter3 of HF course https://huggingface.co/course/chapter3/4?fw=pt    </span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="co"># {'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="co">#  'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="co">#  'labels': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], id=None),</span></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co">#  'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>{'labels': ClassLabel(num_classes=16, names=array(['CLAY', 'GRVL', 'SAND', 'SHLE', 'SDSN', 'BSLT', 'TPSL', 'SOIL',
        'ROCK', 'GRNT', 'SDCY', 'SLSN', 'CGLM', 'MDSN', 'UNKN', 'COAL'],
       dtype=object), id=None),
 'input_ids': Sequence(feature=Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), length=-1, id=None),
 'token_type_ids': Sequence(feature=Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), length=-1, id=None),
 'attention_mask': Sequence(feature=Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), length=-1, id=None)}</code></pre>
</div>
</div>
<div id="7fa2f84c-d726-4a22-955f-ce5e1779f09a" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>tok_ds[<span class="st">'input_ids'</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>[tensor([    1,  3592, 14432,  8076,     2,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0])]</code></pre>
</div>
</div>
<div id="738d8a5a-87ed-4f0b-83e9-5d3fca3210cf" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># https://huggingface.co/docs/transformers/training</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cde4c295-07a5-4302-bec2-4f695f6d232f" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># from Jeremy's notebook:</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="co"># def compute_metrics(eval_pred):</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="co">#     logits, labels = eval_pred</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="co">#     predictions = np.argmax(logits, axis=-1)</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="co">#     return metric.compute(predictions=predictions, references=labels)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c151d98e-af42-43c5-919b-5b85cf80361b" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Defining the Trainer to compute Custom Loss Function, adapted from [Simple Training with the ü§ó Transformers Trainer, around 840 seconds](https://youtu.be/u--UVvH-LIQ?t=840)</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WeightedLossTrainer(Trainer):</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_loss(<span class="va">self</span>, model, inputs, return_outputs<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Feed inputs to model and extract logits</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> outputs.get(<span class="st">"logits"</span>)</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract Labels</span></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> inputs.get(<span class="st">"labels"</span>)</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define loss function with class weights</span></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>        loss_func <span class="op">=</span> torch.nn.CrossEntropyLoss(weight<span class="op">=</span>class_weights)</span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute loss</span></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_func(logits, labels)</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (loss, outputs) <span class="cf">if</span> return_outputs <span class="cf">else</span> loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="18700e87-9769-4a15-a138-acbce78ad03d" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_metrics(eval_pred):</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> eval_pred.label_ids</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> eval_pred.predictions.argmax(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(labels, predictions, average<span class="op">=</span><span class="st">"weighted"</span>)</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"f1"</span>: f1}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="98f682b7-31cb-4d98-8519-3953f4bd7895" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">"./hf_training"</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span> <span class="co"># 128</span></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">8e-5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="9df5a0c0-e0f0-4952-a1d8-97e2bdab8a56" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span>output_dir,</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span>epochs,</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span>lr,</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>    lr_scheduler_type<span class="op">=</span><span class="st">"cosine"</span>,</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span>batch_size,</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span>batch_size <span class="op">*</span> <span class="dv">2</span>,</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    evaluation_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="bu">len</span>(dds[<span class="st">"train"</span>]),</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>    push_to_hub<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="8ddeb9c9-96d8-4118-9c36-2a5eb86e3a88" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.to(<span class="st">"cuda:0"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The above nay not be strictly necessary, depending on your version of <code>transformers</code>. I bumped into the following issue, which was probably the transformers <a href="https://github.com/nlp-with-transformers/notebooks/issues/31#issuecomment-1075369210">4.11.3 bug</a>: <code>RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)</code></p>
<div id="b8c24545" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>dds[<span class="st">"train"</span>],</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>dds[<span class="st">"test"</span>],</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokz,</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics,</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Using amp half precision backend</code></pre>
</div>
</div>
</section>
<section id="training" class="level2">
<h2 class="anchored" data-anchor-id="training">Training?</h2>
<p>You did read the introduction and its spoiler alert, right?</p>
<div id="ee2f965b-c456-4d60-a9a9-a553eb8a8080" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/abcdef/miniconda/envs/hf/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 92742
  Num Epochs = 5
  Instantaneous batch size per device = 64
  Total train batch size (w. parallel, distributed &amp; accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 7250</code></pre>
</div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
Input <span class="ansi-green-fg">In [51]</span>, in <span class="ansi-cyan-fg">&lt;cell line: 1&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span> <span class="ansi-yellow-bg">trainer</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">train</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda/envs/hf/lib/python3.9/site-packages/transformers/trainer.py:1317</span>, in <span class="ansi-cyan-fg">Trainer.train</span><span class="ansi-blue-fg">(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   1312</span>     <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>model_wrapped <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>model
<span class="ansi-green-fg ansi-bold">   1314</span> inner_training_loop <span style="color:rgb(98,98,98)">=</span> find_executable_batch_size(
<span class="ansi-green-fg ansi-bold">   1315</span>     <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_inner_training_loop, <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_train_batch_size, args<span style="color:rgb(98,98,98)">.</span>auto_find_batch_size
<span class="ansi-green-fg ansi-bold">   1316</span> )
<span class="ansi-green-fg">-&gt; 1317</span> <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">inner_training_loop</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-fg ansi-bold">   1318</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">args</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1319</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">resume_from_checkpoint</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">resume_from_checkpoint</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1320</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">trial</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">trial</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1321</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">ignore_keys_for_eval</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">ignore_keys_for_eval</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1322</span> <span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda/envs/hf/lib/python3.9/site-packages/transformers/trainer.py:1554</span>, in <span class="ansi-cyan-fg">Trainer._inner_training_loop</span><span class="ansi-blue-fg">(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)</span>
<span class="ansi-green-fg ansi-bold">   1552</span>         tr_loss_step <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>training_step(model, inputs)
<span class="ansi-green-fg ansi-bold">   1553</span> <span style="font-weight:bold;color:rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1554</span>     tr_loss_step <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">training_step</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">model</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">inputs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   1556</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> (
<span class="ansi-green-fg ansi-bold">   1557</span>     args<span style="color:rgb(98,98,98)">.</span>logging_nan_inf_filter
<span class="ansi-green-fg ansi-bold">   1558</span>     <span style="font-weight:bold;color:rgb(175,0,255)">and</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> is_torch_tpu_available()
<span class="ansi-green-fg ansi-bold">   1559</span>     <span style="font-weight:bold;color:rgb(175,0,255)">and</span> (torch<span style="color:rgb(98,98,98)">.</span>isnan(tr_loss_step) <span style="font-weight:bold;color:rgb(175,0,255)">or</span> torch<span style="color:rgb(98,98,98)">.</span>isinf(tr_loss_step))
<span class="ansi-green-fg ansi-bold">   1560</span> ):
<span class="ansi-green-fg ansi-bold">   1561</span>     <span style="font-style:italic;color:rgb(95,135,135)"># if loss is nan or inf simply add the average of previous logged losses</span>
<span class="ansi-green-fg ansi-bold">   1562</span>     tr_loss <span style="color:rgb(98,98,98)">+</span><span style="color:rgb(98,98,98)">=</span> tr_loss <span style="color:rgb(98,98,98)">/</span> (<span style="color:rgb(98,98,98)">1</span> <span style="color:rgb(98,98,98)">+</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>state<span style="color:rgb(98,98,98)">.</span>global_step <span style="color:rgb(98,98,98)">-</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_globalstep_last_logged)

File <span class="ansi-green-fg">~/miniconda/envs/hf/lib/python3.9/site-packages/transformers/trainer.py:2183</span>, in <span class="ansi-cyan-fg">Trainer.training_step</span><span class="ansi-blue-fg">(self, model, inputs)</span>
<span class="ansi-green-fg ansi-bold">   2180</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> loss_mb<span style="color:rgb(98,98,98)">.</span>reduce_mean()<span style="color:rgb(98,98,98)">.</span>detach()<span style="color:rgb(98,98,98)">.</span>to(<span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>args<span style="color:rgb(98,98,98)">.</span>device)
<span class="ansi-green-fg ansi-bold">   2182</span> <span style="font-weight:bold;color:rgb(0,135,0)">with</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>autocast_smart_context_manager():
<span class="ansi-green-fg">-&gt; 2183</span>     loss <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">compute_loss</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">model</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">inputs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   2185</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>args<span style="color:rgb(98,98,98)">.</span>n_gpu <span style="color:rgb(98,98,98)">&gt;</span> <span style="color:rgb(98,98,98)">1</span>:
<span class="ansi-green-fg ansi-bold">   2186</span>     loss <span style="color:rgb(98,98,98)">=</span> loss<span style="color:rgb(98,98,98)">.</span>mean()  <span style="font-style:italic;color:rgb(95,135,135)"># mean() to average on multi-gpu parallel training</span>

File <span class="ansi-green-fg">~/miniconda/envs/hf/lib/python3.9/site-packages/transformers/trainer.py:2215</span>, in <span class="ansi-cyan-fg">Trainer.compute_loss</span><span class="ansi-blue-fg">(self, model, inputs, return_outputs)</span>
<span class="ansi-green-fg ansi-bold">   2213</span> <span style="font-weight:bold;color:rgb(0,135,0)">else</span>:
<span class="ansi-green-fg ansi-bold">   2214</span>     labels <span style="color:rgb(98,98,98)">=</span> <span style="font-weight:bold;color:rgb(0,135,0)">None</span>
<span class="ansi-green-fg">-&gt; 2215</span> outputs <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">model</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">inputs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   2216</span> <span style="font-style:italic;color:rgb(95,135,135)"># Save past state if it exists</span>
<span class="ansi-green-fg ansi-bold">   2217</span> <span style="font-style:italic;color:rgb(95,135,135)"># TODO: this needs to be fixed and made cleaner later.</span>
<span class="ansi-green-fg ansi-bold">   2218</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>args<span style="color:rgb(98,98,98)">.</span>past_index <span style="color:rgb(98,98,98)">&gt;</span><span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(98,98,98)">0</span>:

File <span class="ansi-green-fg">~/miniconda/envs/hf/lib/python3.9/site-packages/torch/nn/modules/module.py:1110</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   1106</span> <span style="font-style:italic;color:rgb(95,135,135)"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="ansi-green-fg ansi-bold">   1107</span> <span style="font-style:italic;color:rgb(95,135,135)"># this function, and just call forward.</span>
<span class="ansi-green-fg ansi-bold">   1108</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> (<span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_backward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_forward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_forward_pre_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_backward_hooks
<span class="ansi-green-fg ansi-bold">   1109</span>         <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_forward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1110</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">forward_call</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(0,135,0)" class="ansi-yellow-bg">input</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   1111</span> <span style="font-style:italic;color:rgb(95,135,135)"># Do not call functions when jit is used</span>
<span class="ansi-green-fg ansi-bold">   1112</span> full_backward_hooks, non_full_backward_hooks <span style="color:rgb(98,98,98)">=</span> [], []

File <span class="ansi-green-fg">~/miniconda/envs/hf/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1279</span>, in <span class="ansi-cyan-fg">DebertaV2ForSequenceClassification.forward</span><span class="ansi-blue-fg">(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)</span>
<span class="ansi-green-fg ansi-bold">   1271</span> <span style="color:rgb(175,0,0)">r</span><span style="font-style:italic;color:rgb(175,0,0)">"""</span>
<span class="ansi-green-fg ansi-bold">   1272</span> <span style="font-style:italic;color:rgb(175,0,0)">labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):</span>
<span class="ansi-green-fg ansi-bold">   1273</span> <span style="font-style:italic;color:rgb(175,0,0)">    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,</span>
<span class="ansi-green-fg ansi-bold">   1274</span> <span style="font-style:italic;color:rgb(175,0,0)">    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If</span>
<span class="ansi-green-fg ansi-bold">   1275</span> <span style="font-style:italic;color:rgb(175,0,0)">    `config.num_labels &gt; 1` a classification loss is computed (Cross-Entropy).</span>
<span class="ansi-green-fg ansi-bold">   1276</span> <span style="font-style:italic;color:rgb(175,0,0)">"""</span>
<span class="ansi-green-fg ansi-bold">   1277</span> return_dict <span style="color:rgb(98,98,98)">=</span> return_dict <span style="font-weight:bold;color:rgb(0,135,0)">if</span> return_dict <span style="font-weight:bold;color:rgb(175,0,255)">is</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> <span style="font-weight:bold;color:rgb(0,135,0)">None</span> <span style="font-weight:bold;color:rgb(0,135,0)">else</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>config<span style="color:rgb(98,98,98)">.</span>use_return_dict
<span class="ansi-green-fg">-&gt; 1279</span> outputs <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">deberta</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-fg ansi-bold">   1280</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">input_ids</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1281</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">token_type_ids</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">token_type_ids</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1282</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">attention_mask</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">attention_mask</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1283</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">position_ids</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">position_ids</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1284</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">inputs_embeds</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">inputs_embeds</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1285</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">output_attentions</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">output_attentions</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1286</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">output_hidden_states</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">output_hidden_states</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1287</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">return_dict</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">return_dict</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1288</span> <span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   1290</span> encoder_layer <span style="color:rgb(98,98,98)">=</span> outputs[<span style="color:rgb(98,98,98)">0</span>]
<span class="ansi-green-fg ansi-bold">   1291</span> pooled_output <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>pooler(encoder_layer)

File <span class="ansi-green-fg">~/miniconda/envs/hf/lib/python3.9/site-packages/torch/nn/modules/module.py:1110</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   1106</span> <span style="font-style:italic;color:rgb(95,135,135)"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="ansi-green-fg ansi-bold">   1107</span> <span style="font-style:italic;color:rgb(95,135,135)"># this function, and just call forward.</span>
<span class="ansi-green-fg ansi-bold">   1108</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> (<span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_backward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_forward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_forward_pre_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_backward_hooks
<span class="ansi-green-fg ansi-bold">   1109</span>         <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_forward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1110</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">forward_call</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(0,135,0)" class="ansi-yellow-bg">input</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   1111</span> <span style="font-style:italic;color:rgb(95,135,135)"># Do not call functions when jit is used</span>
<span class="ansi-green-fg ansi-bold">   1112</span> full_backward_hooks, non_full_backward_hooks <span style="color:rgb(98,98,98)">=</span> [], []

File <span class="ansi-green-fg">~/miniconda/envs/hf/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1042</span>, in <span class="ansi-cyan-fg">DebertaV2Model.forward</span><span class="ansi-blue-fg">(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)</span>
<span class="ansi-green-fg ansi-bold">   1039</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> token_type_ids <span style="font-weight:bold;color:rgb(175,0,255)">is</span> <span style="font-weight:bold;color:rgb(0,135,0)">None</span>:
<span class="ansi-green-fg ansi-bold">   1040</span>     token_type_ids <span style="color:rgb(98,98,98)">=</span> torch<span style="color:rgb(98,98,98)">.</span>zeros(input_shape, dtype<span style="color:rgb(98,98,98)">=</span>torch<span style="color:rgb(98,98,98)">.</span>long, device<span style="color:rgb(98,98,98)">=</span>device)
<span class="ansi-green-fg">-&gt; 1042</span> embedding_output <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">embeddings</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-fg ansi-bold">   1043</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">input_ids</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">input_ids</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1044</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">token_type_ids</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">token_type_ids</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1045</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">position_ids</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">position_ids</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1046</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">mask</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">attention_mask</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1047</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">inputs_embeds</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">inputs_embeds</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   1048</span> <span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   1050</span> encoder_outputs <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>encoder(
<span class="ansi-green-fg ansi-bold">   1051</span>     embedding_output,
<span class="ansi-green-fg ansi-bold">   1052</span>     attention_mask,
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-fg ansi-bold">   1055</span>     return_dict<span style="color:rgb(98,98,98)">=</span>return_dict,
<span class="ansi-green-fg ansi-bold">   1056</span> )
<span class="ansi-green-fg ansi-bold">   1057</span> encoded_layers <span style="color:rgb(98,98,98)">=</span> encoder_outputs[<span style="color:rgb(98,98,98)">1</span>]

File <span class="ansi-green-fg">~/miniconda/envs/hf/lib/python3.9/site-packages/torch/nn/modules/module.py:1110</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   1106</span> <span style="font-style:italic;color:rgb(95,135,135)"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="ansi-green-fg ansi-bold">   1107</span> <span style="font-style:italic;color:rgb(95,135,135)"># this function, and just call forward.</span>
<span class="ansi-green-fg ansi-bold">   1108</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> (<span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_backward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_forward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_forward_pre_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_backward_hooks
<span class="ansi-green-fg ansi-bold">   1109</span>         <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_forward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1110</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">forward_call</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(0,135,0)" class="ansi-yellow-bg">input</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   1111</span> <span style="font-style:italic;color:rgb(95,135,135)"># Do not call functions when jit is used</span>
<span class="ansi-green-fg ansi-bold">   1112</span> full_backward_hooks, non_full_backward_hooks <span style="color:rgb(98,98,98)">=</span> [], []

File <span class="ansi-green-fg">~/miniconda/envs/hf/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:875</span>, in <span class="ansi-cyan-fg">DebertaV2Embeddings.forward</span><span class="ansi-blue-fg">(self, input_ids, token_type_ids, position_ids, mask, inputs_embeds)</span>
<span class="ansi-green-fg ansi-bold">    872</span>         mask <span style="color:rgb(98,98,98)">=</span> mask<span style="color:rgb(98,98,98)">.</span>unsqueeze(<span style="color:rgb(98,98,98)">2</span>)
<span class="ansi-green-fg ansi-bold">    873</span>     mask <span style="color:rgb(98,98,98)">=</span> mask<span style="color:rgb(98,98,98)">.</span>to(embeddings<span style="color:rgb(98,98,98)">.</span>dtype)
<span class="ansi-green-fg">--&gt; 875</span>     embeddings <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">embeddings</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">mask</span>
<span class="ansi-green-fg ansi-bold">    877</span> embeddings <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>dropout(embeddings)
<span class="ansi-green-fg ansi-bold">    878</span> <span style="font-weight:bold;color:rgb(0,135,0)">return</span> embeddings

<span class="ansi-red-fg">RuntimeError</span>: The size of tensor a (768) must match the size of tensor b (128) at non-singleton dimension 3</pre>
</div>
</div>
</div>
</section>
</section>
<section id="stocktake-and-conclusion" class="level1">
<h1>Stocktake and conclusion</h1>
<p>So, as announced at the start of this post, we hit a pothole in our journey.</p>
<pre class="text"><code>RuntimeError: The size of tensor a (768) must match the size of tensor b (128) at non-singleton dimension 3</code></pre>
<p>Where the number (768) comes from is a bit of a mystery. I gather from Googling that this may have to do with the embedding of the Deberta model we are trying to fine tune, but I may be off the mark.</p>
<p>It is probably something at which an experience NLP practitioner will roll their eyes.</p>
<p>That‚Äôs OK, We‚Äôll get there.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(darkModeDefault) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    }
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/jmp75\.github\.io\/work-blog\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>¬© Copyright 2022 Jean-Michel Perraud. Except where otherwise noted, all text and images licensed CC-BY-NC 4.0.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>